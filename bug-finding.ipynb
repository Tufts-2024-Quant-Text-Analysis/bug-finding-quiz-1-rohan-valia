{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types==0.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: blis==1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: cachetools==5.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (5.5.0)\n",
      "Requirement already satisfied: catalogue==2.0.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.0.10)\n",
      "Requirement already satisfied: certifi==2024.8.30 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer==3.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: click==8.1.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib==0.20.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.20.0)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.2.2)\n",
      "Requirement already satisfied: confection==0.1.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.1.5)\n",
      "Requirement already satisfied: cymem==2.0.8 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2.0.8)\n",
      "Requirement already satisfied: debugpy==1.8.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (1.8.7)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: executing==2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.1.0)\n",
      "Requirement already satisfied: frozendict==2.4.6 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (2.4.6)\n",
      "Requirement already satisfied: future==1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: html5lib-modern==1.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (1.2)\n",
      "Requirement already satisfied: idna==3.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.28.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (8.28.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (3.1.4)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (5.7.2)\n",
      "Requirement already satisfied: langcodes==3.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (3.4.1)\n",
      "Requirement already satisfied: language_data==1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (1.2.0)\n",
      "Requirement already satisfied: LinkHeader==0.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (0.4.3)\n",
      "Requirement already satisfied: lxml==5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (5.3.0)\n",
      "Requirement already satisfied: marisa-trie==1.2.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (0.1.2)\n",
      "Requirement already satisfied: murmurhash==1.0.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (1.0.10)\n",
      "Requirement already satisfied: MyCapytain==3.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (3.0.2)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (2.0.2)\n",
      "Requirement already satisfied: packaging==24.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (24.1)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (4.3.6)\n",
      "Requirement already satisfied: preshed==3.0.9 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (3.0.9)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (3.0.48)\n",
      "Requirement already satisfied: psutil==6.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (6.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (0.2.3)\n",
      "Requirement already satisfied: pydantic==2.9.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (2.9.2)\n",
      "Requirement already satisfied: pydantic_core==2.23.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (2.23.4)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (2.18.0)\n",
      "Requirement already satisfied: PyLD==2.0.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (2.0.4)\n",
      "Requirement already satisfied: pyparsing==3.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (2024.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (26.2.0)\n",
      "Requirement already satisfied: rdflib==7.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (7.1.0)\n",
      "Requirement already satisfied: rdflib-jsonld==0.6.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (0.6.2)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (2.32.3)\n",
      "Requirement already satisfied: rich==13.9.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (13.9.2)\n",
      "Requirement already satisfied: setuptools==75.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (75.2.0)\n",
      "Requirement already satisfied: shellingham==1.5.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (1.5.4)\n",
      "Requirement already satisfied: six==1.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (1.16.0)\n",
      "Requirement already satisfied: smart-open==7.0.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (7.0.5)\n",
      "Requirement already satisfied: spacy==3.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy==3.0.12 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers==1.0.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (1.0.5)\n",
      "Requirement already satisfied: srsly==2.4.8 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (2.4.8)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (0.6.3)\n",
      "Requirement already satisfied: thinc==8.3.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (8.3.2)\n",
      "Requirement already satisfied: tornado==6.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (6.4.1)\n",
      "Requirement already satisfied: tqdm==4.66.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (4.66.5)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (5.14.3)\n",
      "Requirement already satisfied: typer==0.12.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (0.12.5)\n",
      "Requirement already satisfied: typing==3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (3.7.4.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (2024.2)\n",
      "Requirement already satisfied: urllib3==2.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (2.2.3)\n",
      "Requirement already satisfied: wasabi==1.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (1.1.3)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 81)) (0.2.13)\n",
      "Requirement already satisfied: weasel==0.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 82)) (0.4.1)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 83)) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "f = Path(f\"./tlg0525.tlg001.perseus-eng2.pickle\")\n",
    "\n",
    "def tokenize(df: pd.DataFrame):\n",
    "    model = \"en_core_web_sm\"\n",
    "\n",
    "    nlp = spacy.load(model, disable=[\"ner\"])\n",
    "\n",
    "    df[\"tokens\"] = df[\"unannotated_strings\"].apply(nlp.tokenizer)\n",
    "\n",
    "    raw_texts = [t for t in df[\"unannotated_strings\"]]\n",
    "    annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "    df[\"nlp_docs\"] = list(annotated_texts)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = tokenize(pd.read_pickle(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 1\n",
    "\n",
    "Why is the function `expected_frequency_of_collocation(df: pd.DataFrame, node: str, collocate: str, window_size: int = 1)` returning `0.0` no matter what we pass to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bugged code\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def expected_frequency_of_collocation(df: pd.DataFrame, node: str, collocate: str, window_size: int = 1):\n",
    "    \"\"\"\n",
    "    `node` and `collocate` should be the string representations\n",
    "    of the associated lemmata\n",
    "    \"\"\"\n",
    "\n",
    "    lemmata = [t for t in df['nlp_docs'].explode()]\n",
    "    counter = Counter(lemmata)\n",
    "    node_count = counter[node]\n",
    "    collocate_count = counter[collocate]\n",
    "\n",
    "    return (node_count * collocate_count * window_size) / len(lemmata)\n",
    "\n",
    "expected_freq_the_mainlaind = expected_frequency_of_collocation(df, \"mainland\", \"the\")\n",
    "\n",
    "expected_freq_the_mainlaind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2848751741271176"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed code\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def expected_frequency_of_collocation(df: pd.DataFrame, node: str, collocate: str, window_size: int = 1):\n",
    "    \"\"\"\n",
    "    `node` and `collocate` should be the string representations\n",
    "    of the associated lemmata\n",
    "    \"\"\"\n",
    "    lemmata = [t.lemma_ for t in df['nlp_docs'].explode()]\n",
    "    counter = Counter(lemmata)\n",
    "    node_count = counter[node]\n",
    "    collocate_count = counter[collocate]\n",
    "\n",
    "    return (node_count * collocate_count * window_size) / len(lemmata)\n",
    "\n",
    "expected_freq_the_mainland = expected_frequency_of_collocation(df, \"mainland\", \"the\")\n",
    "\n",
    "expected_freq_the_mainland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 1 analysis and response\n",
    "\n",
    "### The bug occurs in the line \"lemmata = [t for t in df['nlp_docs'].explode()]\", where the current implementation lemmata does not account for the lemmatized words in  string format, but rather only accounts for the token objects. By using \"t.lemma_ for t\" instead of \"t for t\", we can effectively create the lemmata such that the counter correcly counts the frequency of the words using the lemmatized forms and string types, which would allow us to subsequently get the correct counts for the string of the node and collocate word that we pass as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 2\n",
    "\n",
    "Why does the code below not give us the number of occurrences of the token \"the\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bugged code\n",
    "\n",
    "observed_freq_the = df['tokens'].str.find('the')\n",
    "\n",
    "observed_freq_the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Fixed code\n",
    "\n",
    "observed_freq_the = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == \"the\"])\n",
    "observed_freq_the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 2 analysis and response\n",
    "\n",
    "### In this case the bug occurs in the line \"observed_freq_the = df['tokens'].str.find('the')\", where it returns NaN because the data in the df[\"tokens\"] are  token objects, but the str.find() operation intends for the data to be in string format. The line of code also would simply find the first entry of \"the\" in the tokens section of the dataframe, which would not give the number of occurences of \"the.\" Therefore, the correct approach would be to employ a similar approach to Bug 1, where you would iterate through the tokens in the nlp docs and use t.lemma_ to check if the lemma of each token is \"the,\" where it would then add it to the list. Finally, taking the length of the list would the total number of occurences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 3\n",
    "\n",
    "How is `o11` greater than `r1`, and why is our `o12` negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bugged code\n",
    "\n",
    "node = \"mainland\"\n",
    "collocate = \"the\"\n",
    "\n",
    "def count_ngram_collocations(x, w1, w2, l_size: int = 1, r_size: int = 1):\n",
    "    lemmata = [t.lemma_ for t in x]\n",
    "\n",
    "    # the right-hand side of a slice in Python is exclusive, so we add 1 to make sure\n",
    "    # we're actually getting one element to the right\n",
    "\n",
    "    chunked_lemmata = [lemmata[i - l_size:i + r_size + 1] for i in range(0, len(lemmata))]\n",
    "    \n",
    "    cooccurrences = [1 for l in chunked_lemmata if w1 in l and w2 in l]\n",
    "\n",
    "    return sum(cooccurrences)\n",
    "\n",
    "r1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == node])\n",
    "r2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != node])\n",
    "c1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == collocate])\n",
    "c2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != collocate])\n",
    "\n",
    "o11 = df[\"nlp_docs\"].apply(count_ngram_collocations, args=(node, collocate)).sum()\n",
    "o12 = r1 - o11\n",
    "o21 = c1 - o11\n",
    "\n",
    "print(f\"r1: {r1}, r2: {r2}, c1: {c1}, c2: {c2}, o11: {o11}, o12: {o12}, o21: {o21}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1: 38, r2: 311516, c1: 26932, c2: 284622, o11: 23, o12: 15, o21: 26909\n"
     ]
    }
   ],
   "source": [
    "# Fixed code\n",
    "\n",
    "node = \"mainland\"\n",
    "collocate = \"the\"\n",
    "\n",
    "def count_ngram_collocations(x, w1, w2, l_size: int = 1, r_size: int = 1):\n",
    "    lemmata = [t.lemma_ for t in x]\n",
    "\n",
    "    indexes = [i for i, lemma in enumerate(lemmata) if lemma == w1]\n",
    "\n",
    "    cooccurrences = 0\n",
    "\n",
    "    for i in indexes:\n",
    "        left = max(i - l_size, 0)\n",
    "        right = min(i + r_size + 1, len(lemmata))\n",
    "        window = lemmata[left:right]\n",
    "\n",
    "        if w2 in window:\n",
    "            cooccurrences += 1\n",
    "\n",
    "    return cooccurrences\n",
    "\n",
    "def count_ngram_non_collocations(x, w1, w2, l_size: int = 1, r_size: int = 1):\n",
    "    lemmata = [t.lemma_ for t in x]\n",
    "\n",
    "    indexes = [i for i, lemma in enumerate(lemmata) if lemma == w1]\n",
    "\n",
    "    non_cooccurrences = 0\n",
    "\n",
    "    for i in indexes:\n",
    "        left = max(i - l_size, 0)\n",
    "        right = min(i + r_size + 1, len(lemmata))\n",
    "        window = lemmata[left:right]\n",
    "\n",
    "        if w2 not in window:\n",
    "            non_cooccurrences += 1\n",
    "\n",
    "    return non_cooccurrences\n",
    "\n",
    "\n",
    "r1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == node])\n",
    "r2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != node])\n",
    "c1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == collocate])\n",
    "c2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != collocate])\n",
    "\n",
    "o11 = df[\"nlp_docs\"].apply(count_ngram_collocations, args=(node, collocate)).sum()\n",
    "o12 = df[\"nlp_docs\"].apply(count_ngram_non_collocations, args=(node, collocate)).sum()\n",
    "o21 = c1 - o11\n",
    "\n",
    "print(f\"r1: {r1}, r2: {r2}, c1: {c1}, c2: {c2}, o11: {o11}, o12: {o12}, o21: {o21}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 3 analysis and response\n",
    "\n",
    "### The reason that o11 (number of cooccurences of the node and collocate) exceeds r1 (number of instances of the node) is because of how the window surrounding the node is calculated in the count_ngram_collocations function. In the bugged code, it leads to overcounting of coocccurences, where there are potential overlaps of the windows that would leave to collocates being accounted for more than once. In the refined count_ngram_collocations, the \"indexes\" list in the fixed code correctly stores the index of each node,and the function subsequently creates a window for each node to ensure that each instance of a collocate is correctly counted uniquely. Furthermore, the fact that o12 (number of non cooccurences) is negative is attested to this error, where since o12 = r1 - o11, and o11 currently exceeds r1. To recalculate the number of non cooccurrences, the implementation of a count_ngram_non_collocations function helps explicitly count the instances where the collocate is not present in a method similar to count_ngram_collocations. This calculation is then used to create our o12 value in a method that mirrors our o11 calculation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
